{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e71b3c7-4f61-4f58-9348-2a7e90b68a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd           # Handle tabular survey data (DataFrame-based pipeline)\n",
    "import numpy as np           # Load trained machine learning models from disk\n",
    "\n",
    "from joblib import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f28e8741-4f42-4131-9820-e32d6d54a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ai_governance_readiness(\n",
    "    df,\n",
    "    # DataFrame containing the survey responses\n",
    "\n",
    "    items=(\"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\"),\n",
    "    # Survey items used to measure AI governance vision\n",
    "\n",
    "    method=\"mean\",\n",
    "    # Method used to compute the score (mean of the items),\n",
    "    # kept for conceptual clarity even if only one method is currently used\n",
    "\n",
    "    score_col=\"AI_Governance_readiness_score\",\n",
    "    # Name of the column that will store the raw AI governance vision score\n",
    "\n",
    "    pct_col=\"AI_Governance_readiness_Pct\",\n",
    "    # Name of the column that will store the percentage score\n",
    "\n",
    "    scale_min=1,\n",
    "    # Minimum value of the Likert scale used in the questionnaire\n",
    "\n",
    "    scale_max=4\n",
    "    # Maximum value of the Likert scale used in the questionnaire\n",
    "):\n",
    "    # -------------------------------------------------\n",
    "    # Step 1: Compute the raw AI governance vision score\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # Compute the row-wise mean of the VUTAI items\n",
    "    # Each row corresponds to one institution or respondent\n",
    "    score = df[list(items)].mean(axis=1)\n",
    "\n",
    "    # Store the raw score in the DataFrame\n",
    "    df[score_col] = score\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Step 2: Convert the raw score into a percentage\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    # Transform the raw score into a 0–100 percentage\n",
    "    # This makes the result easier to interpret and compare\n",
    "    df[pct_col] = ((score - scale_min) / (scale_max - scale_min)) * 100\n",
    "\n",
    "    # Return the DataFrame with the computed scores\n",
    "    return df\n",
    "\n",
    "\n",
    "def interpret_readiness_pct(pct):\n",
    "    # This function converts a percentage score\n",
    "    # into a qualitative interpretation\n",
    "\n",
    "    # If the score is below 33%, AI governance vision is low\n",
    "    if pct < 33:\n",
    "        return \"Low AI Governance Readiness\"\n",
    "\n",
    "    # If the score is between 33% and 66%, vision is moderate\n",
    "    elif pct < 66:\n",
    "        return \"Moderate AI Governance Readiness\"\n",
    "\n",
    "    # If the score is 66% or higher, vision is high\n",
    "    else:\n",
    "        return \"High AI Governance Readiness\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af725375-39cf-4497-aa50-670140b988ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for AIGR1: ML_BestModel_AIGR_AIGR1_RidgeRegression.joblib\n",
      "Loaded best model for AIGR2: ML_BestModel_AIGR_AIGR2_RidgeRegression.joblib\n",
      "Loaded best model for AIGR3: ML_BestModel_AIGR_AIGR3_RidgeRegression.joblib\n",
      "Loaded best model for AIGR4: ML_BestModel_AIGR_AIGR4_RidgeRegression.joblib\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Feature configuration for ML-based AI governance prediction\n",
    "# ============================================================\n",
    "\n",
    "FEATURE_ORDER = {\n",
    "    \"OAC\": [\"OAC1\", \"OAC2\", \"OAC3\", \"OAC4\"],\n",
    "    \"DIR\": [\"DIR1\", \"DIR2\", \"DIR3\", \"DIR4\"],\n",
    "    \"RAI\": [\"RAI1\", \"RAI2\", \"RAI3\", \"RAI4\"],\n",
    "    \"PVO\": [\"PVO1\", \"PVO2\", \"PVO3\", \"PVO4\"],\n",
    "    \"EST\": [\"EST1\", \"EST2\", \"EST3\", \"EST4\"]\n",
    "}\n",
    "\n",
    "# Ordered list of input features used by the trained ML models.\n",
    "# IMPORTANT: The order must be exactly the same as during training,\n",
    "# otherwise, the predictions will be incorrect.\n",
    "# ============================================================\n",
    "# Required libraries for model loading and file handling\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from joblib import load\n",
    "\n",
    "# Model storage configuration\n",
    "MODEL_DIR = \"Models\"\n",
    "# Path to the directory where trained ML models are stored\n",
    "loaded_models = {}\n",
    "\n",
    "# We only care about predicting the three vision items\n",
    "READINESS_TARGETS = [\"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\"]\n",
    "\n",
    "for target in READINESS_TARGETS:\n",
    "\n",
    "    # Find the saved model file for this target\n",
    "    matching_files = [\n",
    "        f for f in os.listdir(MODEL_DIR)\n",
    "        if f.startswith(f\"ML_BestModel_AIGR_{target}_\") and f.endswith(\".joblib\")\n",
    "    ]\n",
    "\n",
    "    if len(matching_files) == 0:\n",
    "        raise FileNotFoundError(f\"No saved best model found for {target}\")\n",
    "\n",
    "    if len(matching_files) > 1:\n",
    "        raise ValueError(f\"Multiple models found for {target}: {matching_files}\")\n",
    "\n",
    "    model_file = matching_files[0]\n",
    "    model_path = os.path.join(MODEL_DIR, model_file)\n",
    "\n",
    "    # Load model\n",
    "    loaded_models[target] = {\n",
    "        \"model\": load(model_path),\n",
    "        \"features\": FEATURE_ORDER\n",
    "    }\n",
    "    \n",
    "# Confirmation message to ensure correct model loading\n",
    "    \n",
    "    print(f\"Loaded best model for {target}: {model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1690c-3ac0-4de8-8a41-74a40dc19121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b292afe-a258-42d8-82d5-990fc0d88294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the vision score of M5 University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d9831f2-0c72-4dd7-a8f0-fed457e4141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 28)\n",
      "['OAC1', 'OAC2', 'OAC3', 'OAC4', 'DIR1', 'DIR2', 'DIR3', 'DIR4', 'RAI1', 'RAI2', 'RAI3', 'RAI4', 'PVO1', 'PVO2', 'PVO3', 'PVO4', 'IP1', 'IP2', 'IP3', 'IP4', 'EST1', 'EST2', 'EST3', 'EST4', 'AIGR1', 'AIGR2', 'AIGR3', 'AIGR4']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Used for numerical operations if needed later in the pipeline\n",
    "import pandas as pd  # Used to load and manipulate tabular data (DataFrame structure)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"Data_PLS.xlsx\")\n",
    "\n",
    "# Sanity check\n",
    "print(df.shape) \n",
    "# Print the dataset dimensions (number of rows and columns)\n",
    "print(df.columns.tolist())\n",
    "# Print the list of column names to verify correct data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46342a42-8f6c-4306-833a-2626995b6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Vision score and percentage on training data\n",
    "df = compute_ai_governance_readiness(\n",
    "    df,\n",
    "    # Input DataFrame containing the survey responses\n",
    "    items=(\"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\"),\n",
    "    \n",
    "     # Survey items used to compute the AI governance vision score\n",
    "    score_col=\"AI_Governance_readiness_score\",\n",
    "    \n",
    "    # Column name for the computed raw vision score\n",
    "    pct_col=\"AI_Governance_readiness_Pct\",\n",
    "      # Column name for the computed percentage score\n",
    "    \n",
    "    scale_min=1,\n",
    "     # Minimum value of the Likert scale\n",
    "    \n",
    "    scale_max=5\n",
    "     # Minimum value of the Likert scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e472bdc2-0b94-412c-ab1d-24b1ab883c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AI Governance Readiness (mean): 3.818\n",
      "Standard deviation: 0.854\n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics for AI governance vision (raw score)\n",
    "\n",
    "overall_readiness_mean = df[\"AI_Governance_readiness_score\"].mean()\n",
    "# Compute the average AI governance vision score across all observationsoverall_vision_std = df[\"AI_Governance_Vision\"].std()\n",
    "\n",
    "overall_readiness_std = df[\"AI_Governance_readiness_score\"].std()\n",
    "# Compute the standard deviation of the AI governance vision score\n",
    "\n",
    "print(f\"Overall AI Governance Readiness (mean): {overall_readiness_mean:.3f}\")\n",
    "# Display the mean raw vision score with three decimal precision\n",
    "print(f\"Standard deviation: {overall_readiness_std:.3f}\")\n",
    "# Display the standard deviation of the raw vision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8661048-b6a5-430d-a575-880a686c841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AI Governance Readiness (%): 70.4%\n",
      "Standard deviation (%): 21.4%\n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics for AI governance vision (percentage score)\n",
    "\n",
    "overall_readiness_pct_mean = df[\"AI_Governance_readiness_Pct\"].mean()\n",
    "# Compute the average AI governance vision percentage score\n",
    "\n",
    "overall_readiness_pct_std = df[\"AI_Governance_readiness_Pct\"].std()\n",
    "# Compute the standard deviation of the AI governance vision percentage score\n",
    "\n",
    "print(f\"Overall AI Governance Readiness (%): {overall_readiness_pct_mean:.1f}%\")\n",
    "# Display the mean percentage score (rounded to one decimal)\n",
    "\n",
    "print(f\"Standard deviation (%): {overall_readiness_pct_std:.1f}%\")\n",
    "# Display the standard deviation of the percentage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ffcbecc-6b69-4299-9207-0248bfacd77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean readiness Score (1–5)</td>\n",
       "      <td>3.817602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Std readiness Score (1–5)</td>\n",
       "      <td>0.854443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean readiness (%)</td>\n",
       "      <td>70.440051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Std readiness (%)</td>\n",
       "      <td>21.361077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Metric      Value\n",
       "0  Mean readiness Score (1–5)   3.817602\n",
       "1   Std readiness Score (1–5)   0.854443\n",
       "2          Mean readiness (%)  70.440051\n",
       "3           Std readiness (%)  21.361077"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a summary table for AI governance vision\n",
    "\n",
    "# List of reported metrics included in the summary table\n",
    "readiness_summary = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Mean readiness Score (1–5)\",\n",
    "        \"Std readiness Score (1–5)\",\n",
    "        \"Mean readiness (%)\",\n",
    "        \"Std readiness (%)\"\n",
    "    ],\n",
    "    # Corresponding numerical values for each metric\n",
    "    \"Value\": [\n",
    "        overall_readiness_mean,\n",
    "        overall_readiness_std,\n",
    "        overall_readiness_pct_mean,\n",
    "        overall_readiness_pct_std\n",
    "    ]\n",
    "})\n",
    "# Display the summary table\n",
    "readiness_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "312b0ff8-f865-430d-b536-9b7310581a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with a controlled aspect ratio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vision percentage values\n",
    "readiness_pct = df[\"AI_Governance_readiness_Pct\"]\n",
    "\n",
    "# Initialize the figure and axis with a compact horizontal layout\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "\n",
    "# Horizontal boxplot of AI governance vision (%)\n",
    "ax.boxplot(\n",
    "    readiness_pct,\n",
    "    vert=False,\n",
    "    widths=0.4,\n",
    "    patch_artist=False\n",
    ")\n",
    "\n",
    "# Use a horizontal orientation to emphasize score distribution\n",
    "# Labels\n",
    "ax.set_xlabel(\"AI Governance Readiness (%)\")\n",
    "\n",
    "# Axis limits\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Remove y-axis clutter\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Grid\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# ✅ SAVE AS VECTOR FORMATS\n",
    "plt.savefig(\"Results/AI_Governance_Readiness_Boxplot.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"Results/AI_Governance_Readiness_Boxplot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e1cd51f-8404-4eaf-a15c-f64e472e5627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AIGR1</th>\n",
       "      <td>4.455684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIGR2</th>\n",
       "      <td>4.643121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIGR3</th>\n",
       "      <td>4.504793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIGR4</th>\n",
       "      <td>4.773889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_Value\n",
       "AIGR1         4.455684\n",
       "AIGR2         4.643121\n",
       "AIGR3         4.504793\n",
       "AIGR4         4.773889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Feature order definition (by construct)\n",
    "# --------------------------------------------------\n",
    "FEATURE_ORDER = {\n",
    "    \"OAC\": [\"OAC1\", \"OAC2\", \"OAC3\", \"OAC4\"],\n",
    "    \"DIR\": [\"DIR1\", \"DIR2\", \"DIR3\", \"DIR4\"],\n",
    "    \"RAI\": [\"RAI1\", \"RAI2\", \"RAI3\", \"RAI4\"],\n",
    "    \"PVO\": [\"PVO1\", \"PVO2\", \"PVO3\", \"PVO4\"],\n",
    "    \"EST\": [\"EST1\", \"EST2\", \"EST3\", \"EST4\"]\n",
    "}\n",
    "\n",
    "# Flatten feature order into a single list (CRITICAL)\n",
    "FEATURE_LIST = [f for group in FEATURE_ORDER.values() for f in group]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. New input data (one institution / decision unit)\n",
    "# --------------------------------------------------\n",
    "new_data = {\n",
    "    \"OAC1\": 4, \"OAC2\": 5, \"OAC3\": 4, \"OAC4\": 4,\n",
    "    \"DIR1\": 5, \"DIR2\": 4, \"DIR3\": 4, \"DIR4\": 5,\n",
    "    \"RAI1\": 4, \"RAI2\": 4, \"RAI3\": 5, \"RAI4\": 4,\n",
    "    \"PVO1\": 3, \"PVO2\": 4, \"PVO3\": 3, \"PVO4\": 4,\n",
    "    \"EST1\": 4, \"EST2\": 5, \"EST3\": 4, \"EST4\": 4\n",
    "}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Convert input to DataFrame & align columns\n",
    "# --------------------------------------------------\n",
    "new_df = pd.DataFrame([new_data])\n",
    "\n",
    "# Ensure correct column order (same as training)\n",
    "new_df = new_df[FEATURE_LIST]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Generate predictions\n",
    "# --------------------------------------------------\n",
    "predictions = {}\n",
    "\n",
    "for target, content in loaded_models.items():\n",
    "    model = content[\"model\"]\n",
    "    y_pred = model.predict(new_df)\n",
    "    predictions[target] = float(y_pred[0])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Convert predictions to DataFrame (optional)\n",
    "# --------------------------------------------------\n",
    "predictions_df = pd.DataFrame.from_dict(\n",
    "    predictions,\n",
    "    orient=\"index\",\n",
    "    columns=[\"Predicted_Value\"]\n",
    ")\n",
    "\n",
    "predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8a413d3-3b4b-4252-8a84-7f7acd03f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the input features match the expected training features\n",
    "\n",
    "expected = set(FEATURE_LIST)     # ✔ indicator-level features used in training\n",
    "actual = set(new_df.columns)     # ✔ columns in new input data\n",
    "\n",
    "if expected != actual:\n",
    "    missing = expected - actual\n",
    "    extra = actual - expected\n",
    "\n",
    "    raise ValueError(\n",
    "        f\"Feature mismatch detected!\\n\"\n",
    "        f\"Missing features: {missing}\\n\"\n",
    "        f\"Unexpected features: {extra}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d629f6-52c3-4ade-bef0-467e0d3b9ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIGR1</th>\n",
       "      <th>AIGR2</th>\n",
       "      <th>AIGR3</th>\n",
       "      <th>AIGR4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.455684</td>\n",
       "      <td>4.643121</td>\n",
       "      <td>4.504793</td>\n",
       "      <td>4.773889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AIGR1     AIGR2     AIGR3     AIGR4\n",
       "0  4.455684  4.643121  4.504793  4.773889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach predicted target values to the input DataFrame\n",
    "\n",
    "\n",
    "for k, v in predictions.items():\n",
    "    # For each predicted target variable (VUTAI1, VUTAI2, VUTAI3),\n",
    "    # add the predicted value as a new column in the DataFrame\n",
    "    new_df[k] = v\n",
    "    \n",
    "    # Display the predicted vision items (sanity check)\n",
    "\n",
    "new_df[[\"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\"]]\n",
    "# Show predicted values for the three AI governance vision indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e0c2a0b-8789-41b6-aeb5-10229a3eb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall AI governance vision score and percentage from predictions\n",
    "\n",
    "new_df = compute_ai_governance_readiness(\n",
    "    new_df,\n",
    "    # Use the new dataset that now includes predicted VUTAI values\n",
    "    \n",
    "    items=(\"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\"),\n",
    "    # Compute the vision score using the predicted vision items\n",
    "    \n",
    "    score_col=\"AI_Governance_readiness_score\",\n",
    "    # Store the computed raw score in this column\n",
    "    \n",
    "    pct_col=\"AI_Governance_readiness_Pct\",\n",
    "    # Store the computed percentage score in this column\n",
    "    \n",
    "    scale_min=1,\n",
    "    # Minimum Likert scale value used for normalization\n",
    "    scale_max=5\n",
    "    # Maximum Likert scale value used for normalization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b473c691-68da-47b8-8a37-0a73040ec3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the percentage score into an interpretable vision level\n",
    "\n",
    "new_df[\"Readiness_Level\"] = new_df[\"AI_Governance_readiness_Pct\"].apply(\n",
    "    interpret_readiness_pct\n",
    ")\n",
    "# Create a qualitative label (Low / Moderate / High) based on the percentage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06618f1a-b0a9-4eab-992d-d076a877f10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIGR1</th>\n",
       "      <th>AIGR2</th>\n",
       "      <th>AIGR3</th>\n",
       "      <th>AIGR4</th>\n",
       "      <th>AI_Governance_readiness_score</th>\n",
       "      <th>AI_Governance_readiness_Pct</th>\n",
       "      <th>Readiness_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.455684</td>\n",
       "      <td>4.643121</td>\n",
       "      <td>4.504793</td>\n",
       "      <td>4.773889</td>\n",
       "      <td>4.594372</td>\n",
       "      <td>89.859293</td>\n",
       "      <td>High AI Governance Readiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AIGR1     AIGR2     AIGR3     AIGR4  AI_Governance_readiness_score  \\\n",
       "0  4.455684  4.643121  4.504793  4.773889                       4.594372   \n",
       "\n",
       "   AI_Governance_readiness_Pct               Readiness_Level  \n",
       "0                    89.859293  High AI Governance Readiness  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final output table with prediction results\n",
    "\n",
    "final_table = new_df[[\n",
    "    \"AIGR1\", \"AIGR2\", \"AIGR3\",\"AIGR4\",\n",
    "    # Predicted AI governance vision items\n",
    "    \"AI_Governance_readiness_score\",\n",
    "    # Computed overall AI governance vision score (raw scale)\n",
    "    \"AI_Governance_readiness_Pct\",\n",
    "    # Computed AI governance vision score expressed as a percentage\n",
    "    \"Readiness_Level\"\n",
    "    # Qualitative interpretation of the vision score (Low / Moderate / High)\n",
    "]]\n",
    "# Display the final results table\n",
    "final_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae28e-221f-4162-9662-924559545180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea7399-f546-471c-ba37-67cdf24797be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121d207-5173-450f-9047-21fd55286f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7fb4c-2705-4dc1-b282-4ab8736c8bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78bf0b-ec0d-4b9c-a45a-1aebb76fda5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
